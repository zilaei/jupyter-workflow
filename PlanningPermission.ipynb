{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment\n",
    "Notebook uses OpenAI API. Use an existing key or [create a new key](https://platform.openai.com/account/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "# Load logging level from environment or set default level to ERROR\n",
    "env_logging_level = os.environ.get(\"LOGGING_LEVEL\", \"ERROR\")\n",
    "level = getattr(logging, env_logging_level.upper(), logging.ERROR)\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=level)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import Markdown\n",
    "from llama_index import LLMPredictor, ServiceContext, download_loader, VectorStoreIndex\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Llama hub dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFMinerReader = download_loader(\"PDFMinerReader\")\n",
    "loader = PDFMinerReader()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup LLM, vector store and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-003\"))\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.environ.get(\"PLANNING_PERMISSION_FILE_PATH\")\n",
    "if (file_path == None):\n",
    "    raise Exception(\"PLANNING_PERMISSION_FILE_PATH not set\")\n",
    "\n",
    "documents = loader.load_data(file=Path(file_path))\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query single question\n",
    "Example of how to manually query a question.\n",
    "\n",
    "Remove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "source": [
    "%%script echo Skipping cell\n",
    "\n",
    "response = query_engine.query(\"Behöver jag söka bygglov för en altan?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions can be loaded from a JSON file\n",
    "Set optinal environment variable `PLANNING_PERMISSION_QUESTIONS_FILE_PATH=./data/questions.json` to load questions from file.\n",
    "\n",
    "For this cell we measure CPU and wall runtime by setting `%%time`.\n",
    "\n",
    "Example of JSON file:\n",
    "```json\n",
    "{\n",
    "    \"questions\": [\n",
    "        {\n",
    "            \"id\": \"q1\",\n",
    "            \"question\": \"Måste man söka bygglov för flaggstång?\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"q2\",\n",
    "            \"question\": \"Måste man söka bygglov för altan?\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \"Måste man söka bygglov för flaggstång?\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Assistant: <b>\n",
       "Ja, man måste söka bygglov för flaggstång inom detaljplanelagt område.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \"Måste man söka bygglov för altan?\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Assistant: <b>\n",
       "Ja, man måste söka bygglov för altan om den är högre än 1,8 meter, placeras mindre än 4,5 meter från gränsen, eller om den kan betraktas som en volymökning eller väsentligt ändrar fasaden.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \"Vad är frankrikes huvudstad?\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Assistant: <b>\n",
       "Paris.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 7.58 ms, total: 151 ms\n",
      "Wall time: 8.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "file_path = os.environ.get(\"PLANNING_PERMISSION_QUESTIONS_FILE_PATH\")\n",
    "\n",
    "if file_path is not None:\n",
    "    try:\n",
    "        with open(file_path) as f:\n",
    "            data = json.load(f)\n",
    "            questions = data.get(\"questions\", [])\n",
    "            \n",
    "            for question in questions:\n",
    "                query = question.get(\"question\")\n",
    "                print(f\"User: {json.dumps(query, ensure_ascii=False)}\")\n",
    "\n",
    "                response = query_engine.query(query)\n",
    "                display(Markdown(f\"Assistant: <b>{response}</b>\"))\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file {file_path} does not exist.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"The file {file_path} is not in a valid JSON format.\")\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
